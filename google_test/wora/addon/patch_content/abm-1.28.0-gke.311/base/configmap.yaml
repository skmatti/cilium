apiVersion: v1
kind: ConfigMap
metadata:
  name: policy-logging-config
  namespace: kube-system
data:
  policy-logging.conf: |
    maxLogRate: 500
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cilium-config
  namespace: kube-system
data:
  api-rate-limit: '{"endpoint-create": "rate-limit:4/s,auto-adjust:false", "endpoint-delete": "rate-limit:4/s,auto-adjust:false"}'

  # This port value is used by ABM's ansible scripts for cluster health-check.
  # Changing this value will break ABM upgrades.
  agent-health-port: "9876"

  # Identity allocation mode selects how identities are shared between cilium
  # nodes by setting how they are stored. The options are "crd" or "kvstore".
  # - "crd" stores identities in kubernetes as CRDs (custom resource definition).
  #   These can be queried with:
  #     kubectl get ciliumid
  # - "kvstore" stores identities in an etcd kvstore, that is
  #   configured below. Cilium versions before 1.6 supported only the kvstore
  #   backend. Upgrades from these older cilium versions should continue using
  #   the kvstore by commenting out the identity-allocation-mode below, or
  #   setting it to "kvstore".
  identity-allocation-mode: crd
  skip-cnp-status-startup-clean: "false"
  # Disable the usage of CiliumEndpoint CRD
  disable-endpoint-crd: "false"

  # If you want to run cilium in debug mode change this value to true
  debug: "false"
  # The agent can be put into the following three policy enforcement modes
  # default, always and never.
  # https://docs.cilium.io/en/latest/policy/intro/#policy-enforcement-modes
  enable-policy: "default"

  # If you want metrics enabled in all of your Cilium agents, set the port for
  # which the Cilium agents will have their metrics exposed.
  # This option deprecates the "prometheus-serve-addr" in the
  # "cilium-metrics-config" ConfigMap
  # NOTE that this will open the port on ALL nodes where Cilium pods are
  # scheduled.
  prometheus-serve-addr: ":9990"

  # If you want metrics enabled in cilium-operator, set the port for
  # which the Cilium Operator will have their metrics exposed.
  # NOTE that this will open the port on the nodes where Cilium operator pod
  # is scheduled.
  operator-prometheus-serve-addr: ":6942"
  enable-metrics: "true"

  # Enable IPv4 addressing. If enabled, all endpoints are allocated an IPv4
  # address.
  enable-ipv4: "true"

  disable-ipv6-tunnel: "true"

  # Enable IPv6 addressing. If enabled, all endpoints are allocated an IPv6
  # address.
  enable-ipv6: $(ENABLE_IPV6)
  enable-ipv6-ndp: $(ENABLE_IPV6)
  # Users who wish to specify their own custom CNI configuration file must set
  # custom-cni-conf to "true", otherwise Cilium may overwrite the configuration.
  custom-cni-conf: "false"
  enable-bpf-clock-probe: "true"
  # If you want cilium monitor to aggregate tracing for packets, set this level
  # to "low", "medium", or "maximum". The higher the level, the less packets
  # that will be seen in monitor output.
  monitor-aggregation: medium

  # The monitor aggregation interval governs the typical time between monitor
  # notification events for each allowed connection.
  #
  # Only effective when monitor aggregation is set to "medium" or higher.
  monitor-aggregation-interval: 5s

  # The monitor aggregation flags determine which TCP flags which, upon the
  # first observation, cause monitor notifications to be generated.
  #
  # Only effective when monitor aggregation is set to "medium" or higher.
  monitor-aggregation-flags: all
  # Specifies the ratio (0.0-1.0) of total system memory to use for dynamic
  # sizing of the TCP CT, non-TCP CT, NAT and policy BPF maps.
  bpf-map-dynamic-size-ratio: "0.0025"
  # bpf-policy-map-max specifies the maximum number of entries in endpoint
  # policy map (per endpoint)
  bpf-policy-map-max: "16384"
  # bpf-lb-map-max specifies the maximum number of entries in bpf lb service,
  # backend and affinity maps.
  # Tune All LB related bpf map to 512k
  bpf-lb-map-max: "524288"
  # bpf-lb-bypass-fib-lookup instructs Cilium to enable the FIB lookup bypass
  # optimization for nodeport reverse NAT handling.
  bpf-lb-external-clusterip: "false"

  # Pre-allocation of map entries allows per-packet latency to be reduced, at
  # the expense of up-front memory allocation for the entries in the maps. The
  # default value below will minimize memory usage in the default installation;
  # users who are sensitive to latency may consider setting this to "true".
  #
  # This option was introduced in Cilium 1.4. Cilium 1.3 and earlier ignore
  # this option and behave as though it is set to "true".
  #
  # If this value is modified, then during the next Cilium startup the restore
  # of existing endpoints and tracking of ongoing connections may be disrupted.
  # As a result, reply packets may be dropped and the load-balancing decisions
  # for established connections may change.
  #
  # If this option is set to "false" during an upgrade from 1.3 or earlier to
  # 1.4 or later, then it may cause one-time disruptions during the upgrade.
  preallocate-bpf-maps: "false"

  # Regular expression matching compatible Istio sidecar istio-proxy
  # container image names
  sidecar-istio-proxy-image: "cilium/istio_proxy"

  # Name of the cluster. Only relevant when building a mesh of clusters.
  cluster-name: $(CILIUM_CLUSTER_NAME)
  # Unique ID of the cluster. Must be unique across all conneted clusters and
  # in the range of 1 and 255. Only relevant when building a mesh of clusters.
  cluster-id: $(CILIUM_CLUSTER_ID)

  # Encapsulation mode for communication between nodes
  # Possible values:
  #   - disabled
  #   - vxlan (default)
  #   - geneve
  tunnel: $(TUNNEL)

  ipam: "kubernetes"
  enable-endpoint-routes: $(NATIVE_ROUTING) # this flag being true prevents creation of tunnel interface
  blacklist-conflicting-routes: "false"
  enable-local-node-route: "true"

  # DNS Polling periodically issues a DNS lookup for each `matchName` from
  # cilium-agent. The result is used to regenerate endpoint policy.
  # DNS lookups are repeated with an interval of 5 seconds, and are made for
  # A(IPv4) and AAAA(IPv6) addresses. Should a lookup fail, the most recent IP
  # data is used instead. An IP change will trigger a regeneration of the Cilium
  # policy for each endpoint and increment the per cilium-agent policy
  # repository revision.
  #
  # This option is disabled by default starting from version 1.4.x in favor
  # of a more powerful DNS proxy-based implementation, see [0] for details.
  # Enable this option if you want to use FQDN policies but do not want to use
  # the DNS proxy.
  #
  # To ease upgrade, users may opt to set this option to "true".
  # Otherwise please refer to the Upgrade Guide [1] which explains how to
  # prepare policy rules for upgrade.
  #
  # [0] http://docs.cilium.io/en/stable/policy/language/#dns-based
  # [1] http://docs.cilium.io/en/stable/install/upgrade/#changes-that-may-require-action
  tofqdns-enable-poller: "false"

  # wait-bpf-mount makes init container wait until bpf filesystem is mounted
  wait-bpf-mount: "false"

  enable-ipv4-masquerade: $(ENABLE_IPV4_MASQUERADE)
  enable-bpf-masquerade: $(ENABLE_BPF_MASQUERADE)
  # IPv6 Masquerade must always be disabled as we support IPv6 only in Flat Mode.
  enable-ipv6-masquerade: "false"

  enable-xt-socket-fallback: "true"
  install-iptables-rules: "true"
  install-no-conntrack-iptables-rules: "false"

  auto-direct-node-routes: "false"
  auto-direct-node-routes-ipv4: $(AUTO_DIRECT_NODE_ROUTES_IPV4)
  auto-direct-node-routes-ipv6: $(AUTO_DIRECT_NODE_ROUTES_IPV6)
  ipv4-native-routing-cidr: $(CLUSTER_CIDR)
  k8s-require-ipv4-pod-cidr: "true"
  k8s-require-ipv6-pod-cidr: "false"
  enable-endpoint-health-checking: "true"
  cni-uninstall: "false"
  enable-health-checking: "true"
  enable-well-known-identities: "false"
  enable-remote-node-identity: "true"
  synchronize-k8s-nodes: "true"
  operator-api-serve-addr: "127.0.0.1:9234"
  disable-cnp-status-updates: "true"
  disable-network-policy-crd: "true"
  k8s-api-server: $(K8S_API_ENDPOINT)

  # kube-proxy related configs
  kube-proxy-replacement: $(CNI_KP_REPLACE)
  node-port-bind-protection: "true"
  enable-auto-protect-node-port-range: "true"
  enable-external-ips: "true"
  enable-host-port: "true"
  enable-node-port: "true"
  enable-session-affinity: "true"
  kube-proxy-replacement-healthz-bind-address: $(CNI_KP_HEALTHZ_ADDR)
  retry-kube-proxy-healthz-binding: $(CNI_KP_RETRY_HEALTHZ_BINDING)
  enable-host-reachable-services: $(ENABLE_SOCK_LB)
  # enable-host-reachable-services will be replaced by "bpf-lb-sock" later
  bpf-lb-sock: $(ENABLE_SOCK_LB)
  # Only enable socket LB for host namespace due to ASM
  bpf-lb-sock-hostns-only: $(ENABLE_SOCK_LB)

  # Egress gateway
  enable-ipv4-egress-gateway: $(ENABLE_EGRESS_GATEWAY)
  annotate-k8s-node-subnet: "true"

  # MCC
  enable-traffic-steering: $(ENABLE_MCC)

  # Enable Flat IPv4. If enabled pods will be routable in flat mode.
  enable-flat-ipv4: $(ENABLE_FLAT_IPV4)

  # Multi NIC
  enable-google-multi-nic: "$(ENABLE_DPV2MULTINIC)"
  # Allow disabling source IP validation for multi-nic endpoints.
  allow-disable-source-ip-validation: $(ALLOW_DISABLE_SOURCE_IP_VALIDATION)
  # Doesn't filter VLAN traffic based on vlan auto detection.
  vlan-bpf-bypass: "0"

  # hubble configs
  enable-hubble: "true"
  enable-host-firewall: "false"

  synchronize-k8s-windows-nodes: "true"

  enable-gng: $(ENABLE_GNG)

  # Setting true disables auto enablement of fast redirect on >= 5.10 kernel
  enable-host-legacy-routing: "true"

  # DPv2 LB mode
  bpf-lb-mode: $(DPV2LBMODE)

  enable-google-persistent-ip: "false"

  disable-envoy-version-check: "true"
